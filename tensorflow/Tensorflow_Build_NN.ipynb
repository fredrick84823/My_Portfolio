{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# TensorFlow 2 quickstart for experts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNzJc4jTj6G"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/quickstart/advanced\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browser—a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. Run all the notebook code cells: Select *Runtime* > *Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOsVdx6GGHmU"
      },
      "source": [
        "Download and install TensorFlow 2. Import TensorFlow into your program:\n",
        "\n",
        "Note: Upgrade `pip` to install the TensorFlow 2 package. See the [install guide](https://www.tensorflow.org/install) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS7DDTiZGRTo"
      },
      "source": [
        "Import TensorFlow into your program:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqFRS6K07jJs"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Evqx0S22r_"
      },
      "source": [
        "Use `tf.data` to batch and shuffle the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iu_quO024c2"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build the `tf.keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras#model_subclassing):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "outputs": [],
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGih-c2LgbJu"
      },
      "source": [
        "Choose an optimizer and loss function for training: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u48C9WQ774n4"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6A1vcigsIe"
      },
      "source": [
        "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0MqHFb4F_qn"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "Use `tf.GradientTape` to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZACiVqA8KQV"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8YT7UmFgpjV"
      },
      "source": [
        "Test the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIKdEzHAJGt7"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-2pkctU_Ci7"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Tensorflow 2 to build a nn model\n",
        "- Practice with Tensor (Basic object in Tensorflow)\n",
        "- Build nn"
      ],
      "metadata": {
        "id": "oVbR9re2PuHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice with Tensor"
      ],
      "metadata": {
        "id": "I3wy3va8Czf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "W7P6Ta0mP1uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "const = tf.Variable(2.0, name='const')\n",
        "b = tf.Variable(2.0, name='b')\n",
        "c = tf.Variable(1.0, name='c')"
      ],
      "metadata": {
        "id": "uKxHKbFXQWrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = tf.add(b, c, name='d') # d = b + c\n",
        "e = tf.add(c, const, name='e') # e = c + const\n",
        "a = tf.multiply(d, e, name='a') # a = d * e\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F75buyB1QdH2",
        "outputId": "099ab80f-4dda-42d9-f9d3-e49a12308486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=9.0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = tf.Variable(np.arange(0, 10), name='b')\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_DcfeGlQwVR",
        "outputId": "5e384b8d-5d88-4919-971d-633e11da6ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'b:0' shape=(10,) dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.cast(b, tf.float32) + c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Iv-TzbRViC",
        "outputId": "b89dbd13-f346-4e4c-b904-1d0034fef4ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKqv46MERefB",
        "outputId": "8e6f8fbc-6086-4b4c-979b-89d4324eb5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 1, 2, 3, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b[1].assign(10)\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOjMZ6g6Rlbi",
        "outputId": "5eb93a70-05f3-404e-870d-ef642500c3ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'b:0' shape=(10,) dtype=int64, numpy=array([ 0, 10,  2,  3,  4,  5,  6,  7,  8,  9])>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a Neural Network"
      ],
      "metadata": {
        "id": "aVerrgAI3dCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "6xAwMmy0SLs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tE08LmHSheW",
        "outputId": "ee31a3dd-91b4-4947-b208-72839336fc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 隨機從 0 到 y_data的數量生成 batch_size 個數字，把這些數字當作 index\n",
        "# 套用 x_data, y_data 當中\n",
        "def get_batch(x_data, y_data, batch_size):\n",
        "    idxs = np.random.randint(0, len(y_data), batch_size)\n",
        "    return x_data[idxs,:,:], y_data[idxs]"
      ],
      "metadata": {
        "id": "EZXx65wgSq0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 100\n",
        "x_train = x_train / 255.0 # scaler to 0~1\n",
        "x_test = x_test / 255.0 # scaler to 0-1\n",
        "# convert x_test to tensor to pass through model (train data will be converted to\n",
        "# tensors on the fly)\n",
        "x_test = tf.Variable(x_test)"
      ],
      "metadata": {
        "id": "Z9tfHlZmTXsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup weight and bias vaiables for three-layer nn"
      ],
      "metadata": {
        "id": "A9zvDPhoU71q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input layer weights and bias: 784 is input dimensions, 300 is hidden layer's neruon number.\n",
        "W1 = tf.Variable(tf.random.normal([784,300], stddev=0.03), name='W1')\n",
        "b1 = tf.Variable(tf.random.normal([300]), name='b1')\n",
        "# hidden layer weights and bias to the output layer\n",
        "W2 = tf.Variable(tf.random.normal([300,10], stddev=0.03), name='W2')\n",
        "b2 = tf.Variable(tf.random.normal([10]), name='b2')"
      ],
      "metadata": {
        "id": "ng1vj8FXU1Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build model"
      ],
      "metadata": {
        "id": "jxrz4fjhfaWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "def nn_model(x_input, W1, b1 ,W2, b2):\n",
        "    x_input = tf.reshape(x_input, shape=(x_input.shape[0], -1))\n",
        "    # y = (Wx + b) * activation function\n",
        "    x = tf.add(tf.matmul(tf.cast(x_input, tf.float32), W1), b1)\n",
        "    x = tf.nn.relu(x)\n",
        "    outputs = tf.add(tf.matmul(x, W2), b2)\n",
        "    # outputs = tf.nn.softmax(outputs)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "FsscwgKjVbV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define loss function"
      ],
      "metadata": {
        "id": "INWOdwd0fdFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, labels):\n",
        "  # The arguments to softmax_cross_entropy_with_logits are labels and logits.\n",
        "  # The usage of this function in the main training loop will be demonstrated shortly.\n",
        "  # The labels argument is supplied from the one-hot y values that are fed into loss_fn during the training process.\n",
        "  # tf.reduct_mean will calculate the mean of all values in tensor.\n",
        "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=outputs))\n",
        "    return cross_entropy"
      ],
      "metadata": {
        "id": "S84BCKYXdlRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define optimizer"
      ],
      "metadata": {
        "id": "h_a2n6J1jQNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "sP0c09sgjPt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU3avy-TDUFe",
        "outputId": "9c3e4c9f-df69-4b7a-9e03-69a9ee6186c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.008301935>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the network"
      ],
      "metadata": {
        "id": "KiKrOM9eg58l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = int(len(y_train) / batch_size)\n",
        "for epoch in range(epochs):\n",
        "    avg_loss = 0\n",
        "    # 開始從第一個 epoch 迭代，總共會跑600個 epochs\n",
        "    for i in range(total_batch):\n",
        "        # 一個 batch 總共會訓練100筆 data\n",
        "        batch_x, batch_y = get_batch(x_train, y_train, batch_size=batch_size)\n",
        "        batch_x = tf.Variable(batch_x)\n",
        "        # batch_y.shape = (100,)\n",
        "        batch_y = tf.Variable(batch_y)\n",
        "        # after one-hot batch_y.shape = (100, 10)\n",
        "        batch_y = tf.one_hot(batch_y, 10)\n",
        "        with tf.GradientTape() as tape:\n",
        "            # pred.shape = (100, 10)\n",
        "            pred = nn_model(batch_x, W1, b1, W2, b2)\n",
        "            # loss is a scalar, arguments needs to have same dimension.\n",
        "            loss = loss_fn(outputs=pred, labels=batch_y)\n",
        "        # gradients = calculate dL/dw and dL/db （對 loss 和參數做微分）\n",
        "        gradients = tape.gradient(loss, [W1, b1, W2, b2])\n",
        "        # 更新參數（update weights and bias through backpropagation）\n",
        "        optimizer.apply_gradients(zip(gradients, [W1, b1, W2, b2]))\n",
        "        avg_loss += loss / total_batch\n",
        "    # validate training data\n",
        "    train_pred = nn_model(x_train, W1, b1, W2, b2)\n",
        "    train_max_idxs = tf.argmax(train_pred, axis=1)\n",
        "    acc = np.sum(train_max_idxs.numpy()==y_train) / len(y_train)\n",
        "    # validate testing data\n",
        "    test_pred = nn_model(x_test, W1, b1, W2, b2)\n",
        "    y_test_one_hot = tf.one_hot(y_test, 10)\n",
        "    test_loss = loss_fn(outputs=test_pred, labels=y_test_one_hot)\n",
        "    max_idxs = tf.argmax(test_pred, axis=1)\n",
        "    test_acc = np.sum(max_idxs.numpy()==y_test) / len(y_test)\n",
        "    print(f\"Epoch: {epoch+1}, loss={avg_loss:.3f}, , acc={acc:.3f}, val_loss={test_loss:.3f}, val_acc:{test_acc*100:.3f}\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQFe3mHThEzW",
        "outputId": "04f6cee8-bf7d-43ba-a118-3a2acd6f7f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, loss=0.362, , acc=0.939, val_loss=0.211, val_acc:93.680\n",
            "Epoch: 2, loss=0.155, , acc=0.962, val_loss=0.133, val_acc:95.970\n",
            "Epoch: 3, loss=0.108, , acc=0.975, val_loss=0.099, val_acc:96.920\n",
            "Epoch: 4, loss=0.077, , acc=0.981, val_loss=0.090, val_acc:97.210\n",
            "Epoch: 5, loss=0.063, , acc=0.985, val_loss=0.080, val_acc:97.510\n",
            "Epoch: 6, loss=0.046, , acc=0.989, val_loss=0.073, val_acc:97.810\n",
            "Epoch: 7, loss=0.040, , acc=0.991, val_loss=0.067, val_acc:97.990\n",
            "Epoch: 8, loss=0.030, , acc=0.992, val_loss=0.068, val_acc:97.940\n",
            "Epoch: 9, loss=0.025, , acc=0.993, val_loss=0.070, val_acc:97.970\n",
            "Epoch: 10, loss=0.021, , acc=0.995, val_loss=0.067, val_acc:97.970\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(W1.shape)\n",
        "print(b1.shape)\n",
        "print(W2.shape)\n",
        "print(b2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF56Ct8o20ut",
        "outputId": "6c61697c-a7c3-4fea-a339-406d8e494c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 300)\n",
            "(300,)\n",
            "(300, 10)\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RJyOJny-CfFh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3wF5wszaj97Y"
      ],
      "name": "Tensorflow_Build_NN",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}